{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3442d2",
   "metadata": {},
   "source": [
    "# ü§ñ Week 6: Classical Machine Learning for Vision\n",
    "**Objective:** Train and evaluate classical machine learning models on image data.\n",
    "\n",
    "In this assignment, you will:\n",
    "- Load a dataset (e.g. Digits or Fashion-MNIST)\n",
    "- Preprocess and extract features (optional)\n",
    "- Train KNN, SVM, and Decision Tree classifiers\n",
    "- Evaluate and compare their performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f107c53",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Load and Visualize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af002d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits()\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(digits.images[i], cmap='gray')\n",
    "    ax.set_title(f'Label: {digits.target[i]}')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b02e9",
   "metadata": {},
   "source": [
    "## üßπ Step 2: Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cbdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = digits.data  # each image is flattened to 64 features (8x8)\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56c1fa",
   "metadata": {},
   "source": [
    "## üß™ Step 3: Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67bc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print('--- KNN ---')\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print('--- SVM ---')\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "print('--- Decision Tree ---')\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e645b",
   "metadata": {},
   "source": [
    "## üìä Step 4: Compare the Results\n",
    "Which model performed the best? Why?\n",
    "- Think about precision, recall, F1-score.\n",
    "- Consider training speed and complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41deed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your reflection below\n",
    "# Example: I found that SVM had the highest accuracy...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635b2bf",
   "metadata": {},
   "source": [
    "## üìù (Optional) Try Another Dataset: Fashion-MNIST\n",
    "Use TensorFlow/Keras or torchvision to try another dataset.\n",
    "You may need to reshape and preprocess the data.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
